{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse notebook tem como objetivo estender os dados através de trasnformações que dizem respeito ao domínio de aplicação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data = pd.read_csv(\"../../dados/Preprocessed/preprocessed_kaggle.csv\")\n",
    "inpe_data = pd.read_csv(\"../../dados/Preprocessed/preprocessed_inpe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpe_data.columns = ['state', 'city', 'biome', 'days_without_rain', \n",
    "                     'precipitacao', 'risk_of_fire', 'latitude',\n",
    "                     'longitude', 'frp', 'month', 'year', 'day','hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data.columns= ['year', 'state', 'month', 'incidents', 'day']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging new info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region of Brazil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_state = {\"state\": ['amapa', 'tocantins', 'para', 'piaui', 'ceara', 'maranhao',\n",
    "       'mato grosso', 'rio grande do norte', 'sergipe', 'alagoas',\n",
    "       'paraiba', 'bahia', 'minas gerais', 'amazonas', 'roraima',\n",
    "       'rio grande do sul', 'pernambuco', 'rondonia', 'goias',\n",
    "       'rio de janeiro', 'sao paulo', 'espirito santo',\n",
    "       'mato grosso do sul', 'santa catarina', 'parana', 'acre',\n",
    "       'distrito federal'],\n",
    "       \"region\": [\"norte\", \"centro-oeste\", \"norte\", \"nordeste\", \"nordeste\", \n",
    "                  \"nordeste\", \"centro-oeste\", \"nordeste\", \"nordeste\", \"nordeste\",\n",
    "                 \"nordeste\", \"nordeste\", \"centro-oeste\", \"norte\", \"norte\",\n",
    "                 \"sul\", \"nordeste\", \"norte\", \"centro-oeste\", \n",
    "                  \"sudeste\", \"sudeste\", \"sudeste\", \n",
    "                  \"centro-oeste\", \"sul\", \"sul\", \"norte\", \"centro-oeste\"]}\n",
    "\n",
    "inpe_data = inpe_data.merge(pd.DataFrame(region_state), how=\"inner\", on=\"state\")\n",
    "kaggle_data = kaggle_data.merge(pd.DataFrame(region_state), how=\"inner\", on=\"state\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregating inpe_data and kaggle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estados = inpe_data['state'].unique()\n",
    "meses = inpe_data['month'].unique()\n",
    "\n",
    "agregated_data = {\n",
    "    'state': [],\n",
    "    'month': [],\n",
    "    'incidents': [],\n",
    "    'year': [],\n",
    "    'region': []\n",
    "}\n",
    "\n",
    "for estado in estados:\n",
    "    for mes in meses:\n",
    "        aux = inpe_data.loc[inpe_data['month'] == mes].loc[inpe_data['state'] == estado]\n",
    "        agregated_data['incidents'].append(len(aux))\n",
    "        agregated_data['month'].append(mes)\n",
    "        agregated_data['year'].append(2018)\n",
    "        agregated_data['state'].append(estado)\n",
    "        agregated_data['region'].append(inpe_data.loc[inpe_data['state'] == estado]['region'].iloc[0])\n",
    "        \n",
    "agregated_inpe_data = pd.DataFrame(agregated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estados = kaggle_data['state'].unique()\n",
    "\n",
    "kaggle_agregated_data = {\n",
    "    'state': [],\n",
    "    'month': [],\n",
    "    'incidents': [],\n",
    "    'year': [],\n",
    "    'region': [],\n",
    "}\n",
    "\n",
    "for estado in estados:\n",
    "    for mes in range(1, 13, 1):\n",
    "        for ano in range(1998, 2018, 1):\n",
    "            kaggle_agregated_data['incidents'].append(kaggle_data.loc[kaggle_data['state'] == estado].loc[kaggle_data['year'] == ano].loc[kaggle_data['month'] == mes].sum()['incidents'])\n",
    "            kaggle_agregated_data['state'].append(estado)\n",
    "            kaggle_agregated_data['month'].append(mes)\n",
    "            kaggle_agregated_data['year'].append(ano)\n",
    "            kaggle_agregated_data['region'].append(kaggle_data.loc[kaggle_data['state'] == estado]['region'].iloc[0])\n",
    "\n",
    "kaggle_agregated_data = pd.DataFrame(kaggle_agregated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we add 'biome' to agregated datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem here is that kaggle_data do not have a columns about biome. So, my ideia to solve this problem is look to inpe data and try to fill the kaggle dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look to the information carried by state about biome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amapa ['Amazonia']\n",
      "tocantins ['Cerrado' 'Amazonia']\n",
      "para ['Amazonia']\n",
      "piaui ['Caatinga' 'Cerrado']\n",
      "ceara ['Caatinga']\n",
      "maranhao ['Cerrado' 'Amazonia' 'Caatinga']\n",
      "mato grosso ['Cerrado' 'Amazonia' 'Pantanal']\n",
      "rio grande do norte ['Caatinga' 'Mata Atlantica']\n",
      "sergipe ['Mata Atlantica' 'Caatinga']\n",
      "alagoas ['Mata Atlantica' 'Caatinga']\n",
      "paraiba ['Mata Atlantica' 'Caatinga']\n",
      "bahia ['Cerrado' 'Mata Atlantica' 'Caatinga']\n",
      "minas gerais ['Cerrado' 'Mata Atlantica' 'Caatinga']\n",
      "amazonas ['Amazonia']\n",
      "roraima ['Amazonia']\n",
      "rio grande do sul ['Pampa' 'Mata Atlantica']\n",
      "pernambuco ['Caatinga' 'Mata Atlantica']\n",
      "rondonia ['Amazonia' 'Cerrado']\n",
      "goias ['Cerrado' 'Mata Atlantica']\n",
      "rio de janeiro ['Mata Atlantica']\n",
      "sao paulo ['Cerrado' 'Mata Atlantica']\n",
      "espirito santo ['Mata Atlantica']\n",
      "mato grosso do sul ['Cerrado' 'Mata Atlantica' 'Pantanal']\n",
      "santa catarina ['Mata Atlantica']\n",
      "parana ['Mata Atlantica' 'Cerrado']\n",
      "acre ['Amazonia']\n",
      "distrito federal ['Cerrado']\n"
     ]
    }
   ],
   "source": [
    "for state in inpe_data['state'].unique():\n",
    "    print(state, inpe_data.loc[inpe_data['state'] == state]['biome'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Amazonia', 'Cerrado', 'Caatinga', 'Pantanal', 'Mata Atlantica',\n",
       "       'Pampa'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpe_data['biome'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we can do here is just an one hot encoding of 'biome', with true values when the state has the biome and false when it doesnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_and_biomes = {\n",
    "    \"state\": [], 'Amazonia': np.zeros(len(inpe_data['state'].unique())), 'Cerrado': np.zeros(len(inpe_data['state'].unique())),\n",
    "    'Caatinga': np.zeros(len(inpe_data['state'].unique())), 'Pantanal': np.zeros(len(inpe_data['state'].unique())),\n",
    "    'Mata Atlantica': np.zeros(len(inpe_data['state'].unique())), 'Pampa': np.zeros(len(inpe_data['state'].unique()))\n",
    "}\n",
    "\n",
    "count = 0\n",
    "for state in inpe_data['state'].unique():\n",
    "    biomes_list = inpe_data.loc[inpe_data['state'] == state]['biome'].unique()\n",
    "    state_and_biomes['state'].append(state)\n",
    "    for biome in biomes_list:\n",
    "        state_and_biomes[biome][count] = 1\n",
    "    count += 1\n",
    "    \n",
    "state_and_biomes = pd.DataFrame(state_and_biomes)\n",
    "kaggle_agregated_data = kaggle_agregated_data.merge(state_and_biomes, on=\"state\", how=\"inner\")\n",
    "agregated_inpe_data = agregated_inpe_data.merge(state_and_biomes, on=\"state\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we add 'latitude' and 'longitude' to agregated datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main problem here is that kaggle_data do not have a columns about latitude and longitude. So, my ideia to solve this problem is look to take the mean value per state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_lat_long = {'state': [], 'latitude_mean': [], 'longitude_mean': []}\n",
    "\n",
    "for state in inpe_data['state'].unique():\n",
    "    state_to_lat_long['state'].append(state)\n",
    "    state_to_lat_long['latitude_mean'].append(inpe_data.loc[inpe_data['state'] == state]['latitude'].mean())\n",
    "    state_to_lat_long['longitude_mean'].append(inpe_data.loc[inpe_data['state'] == state]['longitude'].mean())\n",
    "    \n",
    "aux_df = pd.DataFrame(state_to_lat_long)\n",
    "kaggle_agregated_data = kaggle_agregated_data.merge(aux_df, on=\"state\", how=\"inner\")\n",
    "agregated_inpe_data = agregated_inpe_data.merge(aux_df, on=\"state\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregated_data = kaggle_agregated_data.append(agregated_inpe_data)\n",
    "\n",
    "agregated_data.to_csv(\"..\\\\..\\\\dados\\\\Feature Engineered\\\\agregated_data.csv\", index=False)\n",
    "inpe_data.to_csv(\"..\\\\..\\\\dados\\\\Feature Engineered\\\\inpe_engineered.csv\", index=False)\n",
    "kaggle_data.to_csv(\"..\\\\..\\\\dados\\\\Feature Engineered\\\\kaggle_engineered.csv\", index=False)\n",
    "agregated_inpe_data.to_csv(\"..\\\\..\\\\dados\\\\Feature Engineered\\\\inpe_agregated_engineered.csv\", index=False)\n",
    "kaggle_agregated_data.to_csv(\"..\\\\..\\\\dados\\\\Feature Engineered\\\\kaggle_agregated_engineered.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
